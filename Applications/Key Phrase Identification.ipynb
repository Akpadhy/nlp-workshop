{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyphrases:\n",
    "\n",
    "### What?\n",
    "- In a given document, the most important topics can be represented as key phrases.\n",
    "- It is also termed as key terms, key segments or simply keywords.\n",
    "- E.g.: \n",
    "\n",
    "\n",
    "### Why?\n",
    "- Need to understand what users are talking about\n",
    "- Huge number of documents like User Reviews, Chat logs, Customer support tickets \n",
    "- Insights to build/improve your product\n",
    "\n",
    "\n",
    "### How?\n",
    "\n",
    "#### Preliminaries\n",
    "- Noun Phrase:\n",
    "A word or group of words containing a noun and functioning in a sentence as subject, object, or prepositional object.\n",
    "    - [We] are attending [NLP Classes].\n",
    "    - [Ram] killed [Ravan].\n",
    "\n",
    "\n",
    "- Term Frequency (TF)\n",
    "The count of a term/phrase in a document. It is calculated as a relative score with the total number of terms in the document.\n",
    "    - In the recent past, the government has taken constructive actions towards terrorism. --> \n",
    "    {the: 2/12, in: 1/12, recent: 1/12, past:1/12, ... }\n",
    "\n",
    "\n",
    "- Inverse Document Frequency (IDF)\n",
    "A word appearing in a lot of documents would be considered less important compared to rare words that appear in fewer documents. \n",
    "    - Doc1: This is a document with tag 1.\n",
    "    - Doc2: However, it is important to have different words.\n",
    "    - Doc3: This is a document with tag 3.\n",
    "    - Document Frequency (DF) {is: 3, this: 2, a: 2, ... }\n",
    "    - Total Documents (N): 3\n",
    "    - Inverse Document Frequency (IDF) = $\\log{\\frac{N}{DF + 1}}$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "### Data Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    import glob\n",
    "    abstract_files = glob.glob(\"AutomaticKeyphraseExtraction/Hulth2003/train/*.abstr\")\n",
    "    full_data = []\n",
    "    for file in abstract_files:\n",
    "        f = open(file, 'rb')\n",
    "        lines = f.readlines()\n",
    "        file_data = \" \".join([str(line.decode(\"utf-8\").strip()) for line in lines])\n",
    "        full_data.append(file_data)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_np_chunks(paragraph):\n",
    "    phrases = []\n",
    "    sents = nltk.sent_tokenize(paragraph)\n",
    "    for sent in sents:\n",
    "        pos_tags = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "        grammar = r\"\"\"\n",
    "          NP: {<PP\\$>?<JJ>*<NN>+} \n",
    "              {<NN>*<NNP>+}                # chunk sequences of proper nouns\n",
    "              {<NN>*<NNS>+}\n",
    "              {<NN>+}\n",
    "        \"\"\"\n",
    "        #{<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "        \n",
    "        chunkParser = nltk.RegexpParser(grammar)\n",
    "        chunked = chunkParser.parse(pos_tags)\n",
    "        for subtree in chunked.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "            phrase = \" \".join([np[0] for np in subtree.leaves()])\n",
    "            phrases.append(phrase)\n",
    "    return phrases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Candidate Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"[^a-z0-9 ]\", \" \", text.lower())\n",
    "    return text.strip()\n",
    "\n",
    "def get_candidate_phrases(full_data):\n",
    "    \n",
    "    doc_phrases = []\n",
    "    for doc in full_data:\n",
    "        phrases = get_np_chunks(doc)\n",
    "        \n",
    "        cleaned_phrases = []\n",
    "        for phrase in phrases:\n",
    "            text = clean_text(phrase)\n",
    "            if len(text) > 1:\n",
    "                cleaned_phrases.append(text)\n",
    "        \n",
    "        doc_phrases.append(cleaned_phrases)\n",
    "    return doc_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = get_candidate_phrases(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Scoring using IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def get_inverse_document_frequency(candidates):\n",
    "    \n",
    "    total_docs = len(candidates)\n",
    "    doc_unique_phrases = []\n",
    "    for datum in candidates:\n",
    "        unique_phrases = list(set(datum))\n",
    "        doc_unique_phrases.extend(unique_phrases)\n",
    "    \n",
    "    doc_freq = Counter(doc_unique_phrases)\n",
    "    \n",
    "    full_unique_phrases = doc_freq.keys()\n",
    "    inv_doc_freq = defaultdict()\n",
    "    for phrase in full_unique_phrases:\n",
    "        inv_doc_freq[phrase] = math.log(total_docs / (1.0 + doc_freq[phrase]))\n",
    "    \n",
    "    return inv_doc_freq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_doc_freq = get_inverse_document_frequency(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def get_keywords(doc_id):\n",
    "    phrases = candidates[doc_id]\n",
    "    phrases_tf = Counter(phrases)\n",
    "    total_tf = len(phrases)\n",
    "    \n",
    "    candidate_phrases = []\n",
    "    for phrase in set(phrases):\n",
    "        phrase_n_score = []\n",
    "        tf = phrases_tf[phrase] / (1.0 * total_tf)\n",
    "        tf_idf = tf * inv_doc_freq[phrase]\n",
    "        \n",
    "        phrase_n_score.append(phrase)\n",
    "        phrase_n_score.append(tf_idf)\n",
    "        candidate_phrases.append(phrase_n_score)\n",
    "    \n",
    "    keywords = sorted(candidate_phrases, key=itemgetter(1), reverse=True)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['organisms', 0.40094245796272204],\n",
       " ['mind independent world', 0.40094245796272204],\n",
       " ['realist conception', 0.40094245796272204],\n",
       " ['thesis', 0.3562232850233707],\n",
       " ['organism', 0.20047122898136102],\n",
       " ['realist idea', 0.20047122898136102],\n",
       " ['additional threat', 0.20047122898136102],\n",
       " ['powerful perspective', 0.20047122898136102],\n",
       " ['selective representing the idea', 0.20047122898136102],\n",
       " ['integrated system', 0.20047122898136102],\n",
       " ['scientific interest', 0.20047122898136102],\n",
       " ['consistent', 0.20047122898136102],\n",
       " ['primary concern', 0.20047122898136102],\n",
       " ['niches', 0.20047122898136102],\n",
       " ['realism', 0.18739170936496863],\n",
       " ['third', 0.16503212289529298],\n",
       " ['latter', 0.1600595203202201],\n",
       " ['profiles', 0.1600595203202201],\n",
       " ['contents', 0.1600595203202201],\n",
       " ['notion', 0.1485538769673578],\n",
       " ['compatibility', 0.1485538769673578],\n",
       " ['things', 0.145479355038186],\n",
       " ['issue', 0.1426725364256173],\n",
       " ['representations', 0.1426725364256173],\n",
       " ['sense', 0.13769993385054446],\n",
       " ['authors', 0.12784891289728054],\n",
       " ['environment', 0.12784891289728054]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keywords(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Selective representing and world-making We discuss the thesis of selective representing-the idea that the contents of the mental representations had by organisms are highly constrained by the biological niches within which the organisms evolved. While such a thesis has been defended by several authors elsewhere, our primary concern here is to take up the issue of the compatibility of selective representing and realism. We hope to show three things. First, that the notion of selective representing is fully consistent with the realist idea of a mind-independent world. Second, that not only are these two consistent, but that the latter (the realist conception of a mind-independent world) provides the most powerful perspective from which to motivate and understand the differing perceptual and cognitive profiles themselves. Third, that the (genuine and important) sense in which organism and environment may together constitute an integrated system of scientific interest poses no additional threat to the realist conception'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Readings:\n",
    "1. https://code.google.com/archive/p/kea-algorithm/\n",
    "2. https://www.r-bloggers.com/key-phrase-extraction-from-tweets/\n",
    "3. https://github.com/snkim/AutomaticKeyphraseExtraction\n",
    "4. https://www.cs.waikato.ac.nz/~ml/publications/2005/chap_Witten-et-al_Windows.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
